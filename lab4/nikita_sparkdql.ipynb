{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1cQE-FrES9g6"
      },
      "source": [
        "# Робота з Spark SQL\n",
        "## Складна аналітика з Spark SQL\n",
        "\n",
        "> Можна виконати або за допомогою чистого `DataFrame` API, `Pandas on Spark` API, або за допомогою чистих `SQL` запитів. Вибір за вами.\n",
        "\n",
        "Ви розробник у компанії **BikeServe**, яка займається орендою велосипедів/скутерів. У вас є певні місця (\"станції\"), де зберігаються ваші велосипеди. Якщо на станції немає вільних місць для велосипедів (хтось уже зарезервував або взяв велосипед) протягом певного періоду часу (`timeslot`), це означає, що бізнес йде чудово. Однак вам потрібно покращити обслуговування клієнтів, пропонуючи користувачам велосипеди, коли та в тому місці, де це для них найважливіше.\n",
        "\n",
        "Ваше завдання — знайти найбільш важливі (\"критичні\") пари станції та періоду часу `(stationId, timeslot)`, щоб ваш бізнес знав, куди і коли доставити більше велосипедів.\n",
        "\n",
        "Ваш результат має бути відсортований за цією *критичністю* у порядку спадання.\n",
        "\n",
        "Набір даних містить:\n",
        "* `register.csv` містить інформацію з вашої IoT системи моніторингу про кількість використаних і вільних слотів на ваших станціях оренди велосипедів. Кожен рядок відповідає одному запису про ситуацію на одній станції в певний момент часу.\n",
        "\n",
        "    Кожен рядок має такий формат:\n",
        "\n",
        "    ```bash\n",
        "    stationId\\ttimestamp\\tusedslots\\tfreeslots\n",
        "    ```\n",
        "    \n",
        "    де `timestamp` має формат `datetime`.\n",
        "\n",
        "    > Перший рядок файлу містить заголовок.\n",
        "    > Деякі дані в наборі даних пошкоджено через тимчасові збої мережі та/або вашої системи моніторингу. Це означає, що деякі рядки характеризуються \"використаними слотами (used slots) = 0\" і \"вільними слотами (free slots) = 0\". **Ці рядки необхідно відфільтрувати** перед виконанням будь-яких операцій.\n",
        "\n",
        "* `input/stations.csv` містить опис станцій.\n",
        "\n",
        "    Кожен рядок має такий формат:\n",
        "\n",
        "    ```bash\n",
        "    stationId\\tlongitude\\ttitude\\tname\n",
        "    ```\n",
        "    > Перший рядок файлу містить заголовок.\n",
        "\n",
        "### Опис завдання\n",
        "\n",
        "Кожна пара \"день тижня – година\" є \"часовим інтервалом\" (`timeslot`) і пов’язана з усіма показаннями моніторингу, пов’язаними з цією парою, незалежно від дати. Наприклад, часовий інтервал `Wednesday - 17` відповідає всім показанням, зробленим у середу з `17:00:00` до `17:59:59`.\n",
        "\n",
        "Станція $S_i$ знаходиться в критичному стані, якщо кількість вільних слотів дорівнює `0` (всі велосипеди на станції заброньовані).\n",
        "\n",
        "*Критичність* станції $S_i$ у часовому інтервалі $T_j$ визначається як:\n",
        "\n",
        "$$\n",
        "\\frac{\\text{кількість записів із числом вільних слотів, яке дорівнює нулю, для пари}_{\\left(S_i,T_j\\right)}}{\\text{загальна кількість записів для пари}_{\\left(S_i,T_j\\right)}}\n",
        "$$\n",
        "\n",
        "необхідно:\n",
        "* Обчислити значення *критичності* для кожної пари $(S_i, T_j)$.\n",
        "* Вибирати лише пари, у яких значення *критичності* перевищує \"мінімальний поріг критичності\".\n",
        "    * `Мінімальний поріг критичності` має бути параметром конфігурації програми.\n",
        "* Зберегти у вихідній папці вибрані записи, використовуючи файли `csv` (із заголовком). Зберегти лише такі атрибути:\n",
        "    * ідентифікатор станції\n",
        "    * день тижня\n",
        "    * година\n",
        "    * критичність\n",
        "    * довгота станції\n",
        "    * широта станції\n",
        "* Зберегти результати за зменшення критичності. Якщо є два або більше записів, що характеризуються однаковим значенням критичності, то додатково відсортувати по ідентифікатору станції (у порядку зростання). Якщо і станція та сама, то сортувати за днем тижня (за зростанням) і, нарешті, за годиною (за зростанням).\n",
        "\n",
        "### Поради та підказки\n",
        "\n",
        "Мова SQL, доступна в Spark SQL, має низку попередньо визначених функцій, одна з яких, `hour(timestamp)`, може використовуватися в запитах SQL або в перетворенні `selectExpr`, щоб вибрати `hour` з заданого позначка часу. Ще одна цікава функція, `date_format(timestamp,format)`, може бути використана для отримання іншої корисної інформації зі стовпця timestamp. Наприклад, у форматі `EE` можна отримати день тижня.\n",
        "\n",
        "```python\n",
        "new_df= df.selectExpr(\"date_format(timestamp,'EE') as weekday hour(timestamp) as hour\")\n",
        "```\n",
        "\n",
        "Щоб вказати, що роздільником вхідних файлів CSV є спеціальний символ `tab`, установіть параметр роздільника на `\\\\t`, викликавши `.option(\"delimiter\", \"\\\\t\")` під час читання вхідних даних."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G5BMo752S9g9"
      },
      "source": [
        "## Конфігурація\n",
        "\n",
        "- `number_cores`: Кількість ядер, виділених під Spark\n",
        "- `memory_gb`: Обʼєм оперативної памʼяті, виділеної під Spark (в Гб)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark"
      ],
      "metadata": {
        "id": "fZkkSmV1fmm7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2588b4f0-06cf-43df-afe2-1dcc22d328fd"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.1.tar.gz (317.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.0/317.0 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.1-py2.py3-none-any.whl size=317488491 sha256=51e5637c028807ea6b21a264335f15c0d31aa45f98544eca055bd1993177f066\n",
            "  Stored in directory: /root/.cache/pip/wheels/80/1d/60/2c256ed38dddce2fdd93be545214a63e02fbd8d74fb0b7f3a6\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PqGQ6CHlS9g-"
      },
      "outputs": [],
      "source": [
        "number_cores = 2\n",
        "memory_gb = 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xqtTApF-S9g_"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "spark = (SparkSession\n",
        "    .builder\n",
        "    .appName('Spark Bikes')\n",
        "    .master(f\"local[{number_cores}]\")\n",
        "    .config(\"spark.driver.memory\", f\"{memory_gb}g\")\n",
        "    .getOrCreate())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HgLdAqngS9g_"
      },
      "source": [
        "## Рішення\n",
        "Прочитайте вміст вхідного файлу `register.csv` і збережіть його у DataFrame.\n",
        "\n",
        "Вхідний файл має заголовок.\n",
        "\n",
        "Схема даних:\n",
        "* station: integer (nullable = true)\n",
        "* timestamp: timestamp (nullable = true)\n",
        "* used_slots: integer (nullable = true)\n",
        "* free_slots: integer (nullable = true)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "z5-hjlpjbfkG",
        "outputId": "592b2f72-ede8-4790-d4a6-5802b62b2015"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-7ab6ffec-fa48-469d-be84-1cb0583ae80b\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-7ab6ffec-fa48-469d-be84-1cb0583ae80b\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving register.csv to register (2).csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bxLf_lBxS9g_"
      },
      "outputs": [],
      "source": [
        "# ваш код\n",
        "register_df = spark.read.csv(\"register.csv\", header=True, inferSchema=True, sep=\"\\t\")\n",
        "\n",
        "# Виведення перших декількох рядків DataFrame\n",
        "register_df.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ma2zBRWhS9hA"
      },
      "source": [
        "Видаліть рядки де одночасно `free_slots = 0` та `used_slots = 0`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dQApvXbBS9hA"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.types import IntegerType\n",
        "from pyspark.sql.functions import udf\n",
        "# ваш код\n",
        "# Фільтрація рядків де одночасно free_slots = 0 та used_slots = 0\n",
        "# Визначення функції для UDF\n",
        "def full_function(free_slots: int) -> int:\n",
        "    if free_slots==0:\n",
        "        return 1\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "spark.udf.register(\"full\", full_function)\n",
        "\n",
        "# Додавання стовпця з логічним маркером\n",
        "register_df.createOrReplaceTempView(\"register_table\")\n",
        "filtered_register_df = spark.sql(\"SELECT *, full(`free_slots`) AS full_station FROM register_table\")\n",
        "\n",
        "# Фільтрація рядків де одночасно free_slots = 0 та used_slots = 0\n",
        "filtered_register_df = filtered_register_df.filter((filtered_register_df.used_slots != 0) | (filtered_register_df.full_station != 1))\n",
        "\n",
        "# Відображення перших декількох записів\n",
        "filtered_register_df.show(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NL4UXwdFS9hA"
      },
      "source": [
        "Нам потрібен логічний маркер, щоб побачити, заповнена станція чи ні. Це можна зробити за допомогою UDF під назвою `full(free_slots: int)`, яка повертає\n",
        "* 1, якщо `free_slots` дорівнює 0\n",
        "* 0, якщо `free_slots` більше 0\n",
        "\n",
        "> Якщо ви використовуєте Pandas on Spark API, то треба самостійно застосувати цю функцію (або переписати її)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aWj9yebJS9hA"
      },
      "outputs": [],
      "source": [
        "def full_function(free_slots: int) -> int:\n",
        "    if free_slots==0:\n",
        "        return 1\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "spark.udf.register(\"full\", full_function)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jEfTQimaS9hA"
      },
      "source": [
        "Створіть DataFrame з такою схемою:\n",
        "* station: integer (nullable = true)\n",
        "* dayofweek: string (nullable = true)\n",
        "* hour: integer (nullable = true)\n",
        "* fullstatus: integer (nullable = true) - 1 = full, 0 = non-full"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D3QD9ldIS9hA",
        "outputId": "fea5f705-0e10-4216-bb47-26d61bdae94f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+---------+----+----------+\n",
            "|station|dayofweek|hour|fullstatus|\n",
            "+-------+---------+----+----------+\n",
            "|      4| Thursday|  10|         0|\n",
            "|      1|   Monday|  18|         1|\n",
            "|      5|   Friday|   8|         1|\n",
            "|      3|Wednesday|  15|         1|\n",
            "+-------+---------+----+----------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# ваш код\n",
        "from pyspark.sql.types import StructType, StructField, IntegerType, StringType\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "# Створення SparkSession\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"BikeServe\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "# Визначення схеми\n",
        "schema = StructType([\n",
        "    StructField(\"station\", IntegerType(), nullable=True),\n",
        "    StructField(\"dayofweek\", StringType(), nullable=True),\n",
        "    StructField(\"hour\", IntegerType(), nullable=True),\n",
        "    StructField(\"fullstatus\", IntegerType(), nullable=True)\n",
        "])\n",
        "\n",
        "# Створення DataFrame\n",
        "data = [\n",
        "    (4, \"Thursday\", 10, 0),\n",
        "    (1, \"Monday\", 18, 1),\n",
        "    (5, \"Friday\", 8, 1),\n",
        "    (3, \"Wednesday\", 15, 1),\n",
        "]\n",
        "\n",
        "df = spark.createDataFrame(data, schema=schema)\n",
        "\n",
        "# Відображення DataFrame\n",
        "df.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o2pIKqKvS9hA"
      },
      "source": [
        "Визначте одну групу для кожної комбінації `(station, dayofweek, hour)`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gCuxp2XuS9hB",
        "outputId": "041678b0-2d18-48be-8230-30efd4d7f66b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+---------+----+----------+\n",
            "|station|dayofweek|hour|fullstatus|\n",
            "+-------+---------+----+----------+\n",
            "|      4| Thursday|  10|         0|\n",
            "|      1|   Monday|  18|         1|\n",
            "|      5|   Friday|   8|         1|\n",
            "|      3|Wednesday|  15|         1|\n",
            "+-------+---------+----+----------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# ваш код\n",
        "\n",
        "# Визначення груп\n",
        "grouped_df = df.groupBy(\"station\", \"dayofweek\", \"hour\").agg({\"fullstatus\": \"max\"})\n",
        "\n",
        "# Перейменування стовпця з результатами групування\n",
        "grouped_df = grouped_df.withColumnRenamed(\"max(fullstatus)\", \"fullstatus\")\n",
        "\n",
        "# Відображення результатів\n",
        "grouped_df.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HN4QzgAsS9hB"
      },
      "source": [
        "Обчисліть \"критичність\" для кожної групи `(station, dayofweek, hour)`, тобто для кожної пари `(station, timeslot)`.\n",
        "\n",
        "Критичність дорівнює середньому `fullStatus`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J-9oVrd3S9hB",
        "outputId": "e559c6c7-5aeb-4742-c231-7838141a1161"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+---------+----+-----------+\n",
            "|station|dayofweek|hour|criticality|\n",
            "+-------+---------+----+-----------+\n",
            "|      4| Thursday|  10|        0.0|\n",
            "|      1|   Monday|  18|        1.0|\n",
            "|      5|   Friday|   8|        1.0|\n",
            "|      3|Wednesday|  15|        1.0|\n",
            "+-------+---------+----+-----------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# ваш код\n",
        "from pyspark.sql.functions import avg\n",
        "# Групування та обчислення середнього значення fullstatus\n",
        "criticality_df = df.groupBy(\"station\", \"dayofweek\", \"hour\") \\\n",
        "                   .agg(avg(\"fullstatus\").alias(\"criticality\"))\n",
        "\n",
        "# Відображення результатів\n",
        "criticality_df.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G30-D9vHS9hB"
      },
      "source": [
        "Виберіть лише рядки з `criticality > threshold`\n",
        "\n",
        "> `threshold` є деякою бізнес-вимогою, тому візьміть випадкове число від `0.1` до `0.5`, яке вам подобається :)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VcXW_NdnS9hB",
        "outputId": "d2ad3c32-69f0-411c-88bd-e11a94b8a471"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+---------+----+-----------+\n",
            "|station|dayofweek|hour|criticality|\n",
            "+-------+---------+----+-----------+\n",
            "|      1|   Monday|  18|        1.0|\n",
            "|      5|   Friday|   8|        1.0|\n",
            "|      3|Wednesday|  15|        1.0|\n",
            "+-------+---------+----+-----------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "threshold = 0.25\n",
        "\n",
        "# ваш код\n",
        "# Вибір рядків, де criticality > threshold\n",
        "selected_rows = criticality_df.filter(criticality_df.criticality > threshold)\n",
        "\n",
        "# Відображення результату\n",
        "selected_rows.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UnrjjhabS9hB"
      },
      "source": [
        "Прочитайте вміст вхідного файлу `stations.csv` і збережіть його у DataFrame.\n",
        "\n",
        "Вхідний файл має заголовок.\n",
        "\n",
        "Схема даних:\n",
        "* id: integer (nullable = true)\n",
        "* longitude: double (nullable = true)\n",
        "* latitude: double (nullable = true)\n",
        "* name: string (nullable = true)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "nfCCGPVik-k-",
        "outputId": "6f8fcc65-2fb1-44eb-d241-98911409f95d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-66d0741f-8c08-4f9b-8e96-93fc2e62be2c\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-66d0741f-8c08-4f9b-8e96-93fc2e62be2c\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving stations.csv to stations.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PkbDcKYrS9hC",
        "outputId": "802e3cf7-0a24-409e-cf62-674022f483ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- id: integer (nullable = true)\n",
            " |-- longitude: double (nullable = true)\n",
            " |-- latitude: double (nullable = true)\n",
            " |-- name: string (nullable = true)\n",
            "\n",
            "+---+---------+---------+--------------------+\n",
            "| id|longitude| latitude|                name|\n",
            "+---+---------+---------+--------------------+\n",
            "|  1| 2.180019|41.397978|Gran Via Corts Ca...|\n",
            "|  2| 2.176414|41.394381|       Plaza TetuÃ¡n|\n",
            "|  3| 2.181164| 41.39375|             Ali Bei|\n",
            "|  4|   2.1814|41.393364|               Ribes|\n",
            "|  5| 2.180214|41.391072|  Pg LluÃ­s Companys|\n",
            "|  6| 2.180508|41.391272|  Pg LluÃ­s Companys|\n",
            "|  7| 2.183183|41.388867|  Pg LluÃ­s Companys|\n",
            "|  8| 2.183453|41.389044|Passeig lluÃ­s co...|\n",
            "|  9| 2.185294|41.385006|MarquÃ¨s de l\\'Ar...|\n",
            "| 10| 2.185206|41.384875|Avinguda del Marq...|\n",
            "| 11| 2.183622|41.385394|             ComerÃ§|\n",
            "| 12| 2.193939|41.381681|            Trelawny|\n",
            "| 13| 2.195661|41.384522|pg marÃ­tim barce...|\n",
            "| 14| 2.195603|41.384417|     Passeig Maritim|\n",
            "| 15| 2.195706|41.386811|       Avda. Litoral|\n",
            "| 16| 2.195764|41.386869|    Avinguda Litoral|\n",
            "| 17| 2.170775|41.395161|              Girona|\n",
            "| 18|   2.1867|41.398258|       Av. Meridiana|\n",
            "| 19| 2.186697|41.398181|             Padilla|\n",
            "| 20| 2.174139|41.405875|           RossellÃ³|\n",
            "+---+---------+---------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# ваш код\n",
        "# Завантаження даних з файлу stations.csv\n",
        "stations_df = spark.read.csv(\"stations.csv\", header=True, inferSchema=True, sep=\"\\t\")\n",
        "\n",
        "# Відображення схеми даних\n",
        "stations_df.printSchema()\n",
        "\n",
        "# Відображення перших декількох записів\n",
        "stations_df.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZxC2-usFS9hC"
      },
      "source": [
        "Об’єднайте (`JOIN`) вибрані критичні часові інтервали з таблицею станцій, щоб отримати координати станцій"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y8vPiMe_S9hC",
        "outputId": "b74c8ad9-9827-44f4-a1d0-e649660317cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+---------+---------+--------------------+-----------+\n",
            "| id| latitude|longitude|                name|criticality|\n",
            "+---+---------+---------+--------------------+-----------+\n",
            "|  1|41.397978| 2.180019|Gran Via Corts Ca...|        0.0|\n",
            "|  2|41.394381| 2.176414|       Plaza TetuÃ¡n|        0.0|\n",
            "|  3| 41.39375| 2.181164|             Ali Bei|        0.0|\n",
            "|  4|41.393364|   2.1814|               Ribes|        0.0|\n",
            "|  5|41.391072| 2.180214|  Pg LluÃ­s Companys|        0.0|\n",
            "|  6|41.391272| 2.180508|  Pg LluÃ­s Companys|        0.0|\n",
            "|  7|41.388867| 2.183183|  Pg LluÃ­s Companys|        0.0|\n",
            "|  8|41.389044| 2.183453|Passeig lluÃ­s co...|        0.0|\n",
            "|  9|41.385006| 2.185294|MarquÃ¨s de l\\'Ar...|        0.0|\n",
            "| 10|41.384875| 2.185206|Avinguda del Marq...|        0.0|\n",
            "| 11|41.385394| 2.183622|             ComerÃ§|        0.0|\n",
            "| 12|41.381681| 2.193939|            Trelawny|        0.0|\n",
            "| 13|41.384522| 2.195661|pg marÃ­tim barce...|        0.0|\n",
            "| 14|41.384417| 2.195603|     Passeig Maritim|        0.0|\n",
            "| 15|41.386811| 2.195706|       Avda. Litoral|        0.0|\n",
            "| 16|41.386869| 2.195764|    Avinguda Litoral|        0.0|\n",
            "| 17|41.395161| 2.170775|              Girona|        0.0|\n",
            "| 18|41.398258|   2.1867|       Av. Meridiana|        0.0|\n",
            "| 19|41.398181| 2.186697|             Padilla|        0.0|\n",
            "| 20|41.405875| 2.174139|           RossellÃ³|        0.0|\n",
            "+---+---------+---------+--------------------+-----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Об'єднання criticality_df та stations_df за допомогою поля \"station\"\n",
        "joined_df = criticality_df.join(stations_df)\n",
        "\n",
        "# Вибір необхідних стовпців (наприклад, координати станцій та рівень критичності)\n",
        "result_df = joined_df.select(\"id\", \"latitude\", \"longitude\", \"name\", \"criticality\")\n",
        "\n",
        "# Відображення результатів\n",
        "result_df.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nmdb5pXxS9hC"
      },
      "source": [
        "Відсортуйте вміст DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J9aHk8XXS9hC",
        "outputId": "119349ff-a0f0-461d-8c16-de1e050e276d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+---------+---------+--------------------+-----------+\n",
            "| id| latitude|longitude|                name|criticality|\n",
            "+---+---------+---------+--------------------+-----------+\n",
            "|  1|41.397978| 2.180019|Gran Via Corts Ca...|        1.0|\n",
            "|  1|41.397978| 2.180019|Gran Via Corts Ca...|        1.0|\n",
            "|  1|41.397978| 2.180019|Gran Via Corts Ca...|        0.0|\n",
            "|  1|41.397978| 2.180019|Gran Via Corts Ca...|        1.0|\n",
            "|  2|41.394381| 2.176414|       Plaza TetuÃ¡n|        0.0|\n",
            "|  2|41.394381| 2.176414|       Plaza TetuÃ¡n|        1.0|\n",
            "|  2|41.394381| 2.176414|       Plaza TetuÃ¡n|        1.0|\n",
            "|  2|41.394381| 2.176414|       Plaza TetuÃ¡n|        1.0|\n",
            "|  3| 41.39375| 2.181164|             Ali Bei|        1.0|\n",
            "|  3| 41.39375| 2.181164|             Ali Bei|        0.0|\n",
            "|  3| 41.39375| 2.181164|             Ali Bei|        1.0|\n",
            "|  3| 41.39375| 2.181164|             Ali Bei|        1.0|\n",
            "|  4|41.393364|   2.1814|               Ribes|        0.0|\n",
            "|  4|41.393364|   2.1814|               Ribes|        1.0|\n",
            "|  4|41.393364|   2.1814|               Ribes|        1.0|\n",
            "|  4|41.393364|   2.1814|               Ribes|        1.0|\n",
            "|  5|41.391072| 2.180214|  Pg LluÃ­s Companys|        1.0|\n",
            "|  5|41.391072| 2.180214|  Pg LluÃ­s Companys|        0.0|\n",
            "|  5|41.391072| 2.180214|  Pg LluÃ­s Companys|        1.0|\n",
            "|  5|41.391072| 2.180214|  Pg LluÃ­s Companys|        1.0|\n",
            "+---+---------+---------+--------------------+-----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# ваш код\n",
        "# Відсортувати DataFrame за стовпцем \"id\" в порядку зростання\n",
        "sorted_df = result_df.orderBy(\"id\")\n",
        "\n",
        "# Відображення відсортованого DataFrame\n",
        "sorted_df.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iYT3l1cIS9hC"
      },
      "source": [
        "Write to file:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "aUM09slpS9hC"
      },
      "outputs": [],
      "source": [
        "# ваш код\n",
        "sorted_df.write.csv(\"result.csv\", header=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tr2DPwR-S9hC"
      },
      "source": [
        "## Зупинка Spark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7_MVBrRJS9hC"
      },
      "outputs": [],
      "source": [
        "spark.stop()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.6"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}